{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorthrimic Trading with Sentimental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has been on going research in the area of Sentimental Analysis and it's application to stock returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from quantopian.pipeline import Pipeline\n",
    "from quantopian.research import run_pipeline\n",
    "from quantopian.pipeline.filters.morningstar import Q1500US\n",
    "from quantopian.pipeline.data.sentdex import sentiment\n",
    "import blaze\n",
    "import datetime as dt\n",
    "from quantopian.pipeline.data.morningstar import operation_ratios\n",
    "from quantopian.interactive.data.sentdex import sentiment\n",
    "from datetime import timedelta\n",
    "from pytz import timezone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "import talib\n",
    "import statsmodels.api as sm\n",
    "import numpy \n",
    "import pandas as pd\n",
    "import alphalens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for Sentimental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at sample data from the the sample set wee can pull it to see how the sample data is avaliable for a specific company such as Apple. This is to look at the sample data that we have for the sentiment signals for specific companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AAPL_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AAPL_sentiment['sentiment_signal'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process the Data for Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a PCA on the sentiments to determine a best fit line after making an algorithm with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from quantopian.pipeline.data.sentdex import sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    sentiment_factor = sentiment.sentiment_signal.latest\n",
    "    \n",
    "    universe = (Q1500US() & sentiment_factor.notnull())\n",
    "    \n",
    "    pipe = Pipeline(columns ={'Sentiment':sentiment_factor, \n",
    "                              'Shorts': (sentiment_factor <=-2),\n",
    "                              'Longs': (sentiment_factor >=4)}, \n",
    "                    screen = universe)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = run_pipeline(make_pipeline(), start_date = '2014-01-01' , end_date = '2015-12-31')\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import alphalens\n",
    "\"\"\"\"\n",
    "In order to see what values of alpha and expected returns will be given the training time from April 1st 2014 to December 31s, 2015 \n",
    "\"\"\"\"\n",
    "factor_data = alphalens.utils.get_clean_factor_and_forward_returns(factor=result['Sentiment'], \n",
    "                                                                   prices=pricing,\n",
    "                                                                   quantiles=2,\n",
    "                                                                   periods = (3,10,30))\n",
    "alphalens.tears.create_full_tear_sheet(factor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Running backtest on the sentiment with long/ Short strategy to see how it fairs on the market fromJanuary 1st 2015 to January 2018\n",
    "bt = get_backtest('5af254a1d1362c4454073df7')\n",
    "bt.create_full_tear_sheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets = result.index.levels[1].unique()\n",
    "pricing = get_pricing(assets, start_date = '2014-01-01' , end_date = '2015-12-31', fields = 'open_price' )\n",
    "len(assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(result[\"Longs\"],result[\"Sentiment\"],margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result['Sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "print(\"original shape:   \", X.shape)\n",
    "print(\"transformed shape:\", X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = pca.inverse_transform(X_pca)\n",
    "plt.scatter(X, Y, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing alpha for Revenue Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    #Testing results for operation_ratios.revenue_growth\n",
    "\n",
    "    \n",
    "    testing_factor = operation_ratios.revenue_growth.latest\n",
    "    universe = (Q1500US() & testing_factor.notnull())\n",
    "    testing_factor = testing_factor.rank(mask=universe, method ='average')\n",
    "    \n",
    "    pipe = Pipeline(columns ={'testing_factor':testing_factor}, screen = universe)\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "result = run_pipeline(make_pipeline(), start_date = '2015-01-01' , end_date = '2016-01-01')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets = result.index.levels[1].unique()\n",
    "pricing = get_pricing(assets, start_date = '2014-01-01' , end_date = '2015-12-31', fields = 'open_price' )\n",
    "len(assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import alphalens\n",
    "\n",
    "factor_data = alphalens.utils.get_clean_factor_and_forward_returns(factor=result['testing_factor'], \n",
    "                                                                   prices=pricing,\n",
    "                                                                   quantiles=2,\n",
    "                                                                   periods = (3,10,30))\n",
    "alphalens.tears.create_full_tear_sheet(factor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing alpha for Operations Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    #Testing results for operation_ratios.Operations Margin\n",
    "\n",
    "    \n",
    "    testing_factor = operation_ratios.revenue_growth.latest\n",
    "    universe = (Q1500US() & testing_factor.notnull())\n",
    "    testing_factor = testing_factor.rank(mask=universe, method ='average')\n",
    "    \n",
    "    pipe = Pipeline(columns ={'testing_factor':testing_factor}, screen = universe)\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "result = run_pipeline(make_pipeline(), start_date = '2015-01-01' , end_date = '2016-01-01')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets = result.index.levels[1].unique()\n",
    "pricing = get_pricing(assets, start_date = '2014-01-01' , end_date = '2015-12-31', fields = 'open_price' )\n",
    "len(assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import alphalens\n",
    "\n",
    "factor_data = alphalens.utils.get_clean_factor_and_forward_returns(factor=result['testing_factor'], \n",
    "                                                                   prices=pricing,\n",
    "                                                                   quantiles=2,\n",
    "                                                                   periods = (3,10,30))\n",
    "alphalens.tears.create_full_tear_sheet(factor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing combination of all three factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all three factors of Sentiment, Operations margin, and Revenue Growth in algorithm in order to test out the impact of the model overtime with the stock market "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    #Good results for operation_ratios.revenue_growth.latest , operation_ratios.operation_margin.latest , sentiment\n",
    "    # testing_factor = operation_ratios.revenue_growth.latest\n",
    "\n",
    "    \n",
    "    testing_factor1 = operation_ratios.revenue_growth.latest\n",
    "    testing_factor2 = operation_ratios.operation_margin.latest\n",
    "    testing_factor3 = sentiment.sentiment_signal.latest\n",
    "    \n",
    "    universe = (Q1500US() & \n",
    "                testing_factor1.notnull() &\n",
    "               testing_factor2.notnull() &\n",
    "               testing_factor3.notnull())\n",
    "    testing_factor1 = testing_factor1.rank(mask=universe, method ='average')\n",
    "    testing_factor2 = testing_factor2.rank(mask=universe, method ='average')\n",
    "    testing_factor3 = testing_factor3.rank(mask=universe, method ='average')\n",
    "    \n",
    "    testing_factor = testing_factor1 + testing_factor2 +testing_factor3\n",
    "    \n",
    "    testing_quantiles = testing_factor.quantiles(2)\n",
    "    \n",
    "    pipe = Pipeline(columns ={'testing_factor':testing_factor, 'shorts': testing_quantiles.eq(0),'longs': testing_quantiles.eq(1)}, screen = universe)\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "result = run_pipeline(make_pipeline(), start_date = '2013-04-01' , end_date = '2018-05-01')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets = result.index.levels[1].unique()\n",
    "pricing = get_pricing(assets, start_date = '2014-12-31' , end_date = '2016-02-01', fields = 'open_price' )\n",
    "len(assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import alphalens\n",
    "\n",
    "factor_data = alphalens.utils.get_clean_factor_and_forward_returns(factor=result['testing_factor'], \n",
    "                                                                   prices=pricing,\n",
    "                                                                   quantiles=2,\n",
    "                                                                   periods = (3,10,30))\n",
    "alphalens.tears.create_full_tear_sheet(factor_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Running a backtest on running all the factors and weighing them differently\n",
    "bt = get_backtest('5af26eb4c56ef9437dde7384')\n",
    "bt.create_full_tear_sheet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the results of the backtest with the market is that my algorithm did not beat the market and failed to deliver on the returns given sentimental feedback. As can be seen in the back test running a machine learning model for tracking the bears and bulls market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Running a backtest on running all the factors and weighing them differently by developing a bears and bull market.\n",
    "bt = get_backtest('5af27412a56aa7444ec1b896')\n",
    "bt.create_full_tear_sheet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results of the back test we could see that with a 11.3% return from the strategy developed.Although developed a more efficient strategy for creating weighted factors it did not help in beating the market. Although from our previous backtest we could see the long/short strategies that were developed. \n",
    "\n",
    "There we severl limitations which included the number of frictions upon the market. Markets tend to have more frictions and that would affect our overall return. We alsoonly worked with three factors along with sentimental analysis. In the future, it would be best to test and run more factors not just with sentimental analysis as well as using more neural networking strategy to develop the weights for each of the factors needed.Further research could be used and developed for those purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
